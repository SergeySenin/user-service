# Журнал техдолга по сервису пользователей

Фиксирует отложенные задачи и технический долг.
Для записи: категория, описание и детали проблемы, направления решений.

## Формат записи

- Статусы задачи: `[ ]`, `[x]`.
- Блоки: **Описание**, **Что делать**, **Возможные решения**, **Заметки**.

## Записи

### [ ] Новые файлы аватара в S3 не откатываются при сбоях после загрузки
- **Категория:** S3, транзакционность
- **Описание:** В `uploadAvatar` новые ключи сначала загружаются в S3, затем
  обновляется сущность, и удаляются старые объекты. Если на любом шаге после
  `storeObject` (например, при сохранении пользователя) произойдёт исключение,
  новые объекты останутся в бакете, потому что их удаление не предусмотрено ни
  в `uploadResizedVersions`, ни в обработке `userService.save`.
  Это создаёт утечки «осиротевших» файлов.
- **Что делать:** Перенести физическое удаление в S3 на фазу после успешного коммита
  (через `TransactionSynchronizationManager`/`afterCommit`) либо возвращать
  старые ключи в случае ошибки, чтобы данные оставались консистентными.
- **Возможные решения:** Staging → Promote + TTL; S3 Versioning + `versionId`;
  Outbox + воркер (саговая модель); Direct-to-S3 + confirm; after-commit hook;
  локальная компенсация; отдельный реапер/инвентаризация.

### [ ] Частичный успех `deleteAvatarObjects` оставляет данные в неконсистентном состоянии
- **Категория:** S3, обработка ошибок
- **Описание:** Метод удаляет ключи последовательно через `forEach`.
  Если удаление превью пройдёт успешно, а удаление оригинала выбросит
  `FileStorageException`, цикл оборвётся: часть файлов уже стерта, а
  остальные останутся. Исключение поднимется и транзакция БД откатится,
  поэтому пользователь продолжит ссылаться на превью, которого уже нет в хранилище.
- **Что делать:** Собирать результаты удаления, не прерывая цикл на первой ошибке,
  и по завершении принимать решение — повторно удалять оставшиеся ключи или
  аккумулировать ошибки и возвращать агрегированное исключение без потери информации.

### [ ] Нет защиты от гонок при одновременных загрузках, возможны утечки в S3
- **Категория:** Конкурентность, S3
- **Описание:** Сущность `User` не содержит поля `@Version`, а `uploadAvatar`
  работает в схеме «прочитал → залил новые файлы → сохранил → удалил старые».
  Если два клиента загрузят аватар почти одновременно, второй сохранит
  свои ключи, а первый удалит только прежние (`oldAvatarPaths`) и оставит
  новые ключи второго запроса нетронутыми. В итоге в S3 останется
  неиспользуемый набор файлов, а состояние в БД уже другое.
- **Что делать:** Добавить оптимистическую версию для сущности пользователя,
  расширить Liquibase-скрипт демо-данных столбцом `version` со значением по
  умолчанию, реализовать обработку конфликтов версий при загрузке аватара с
  очисткой временных файлов S3 и новым доменным исключением и кодом ошибки,
  задокументировать возможный ответ `409 Conflict` в OpenAPI и README.

### [ ] Отсутствует проверка верхней границы размера загружаемого файла
- **Категория:** Валидация входных данных
- **Описание:** Валидатор гарантирует, что файл не пустой, но не ограничивает 
  его максимальный размер (`getValidatedExtension` проверяет лишь
  `file.getSize() <= 0`). После этого `readFileBytes` считывает содержимое
  полностью в память. Большой или специально сформированный файл приведёт
  к перерасходу памяти/CPU и может положить сервис.
- **Что делать:** Добавить настройку (например, `user.avatar.maxFileSize`)
  и проверять её до чтения в память, а также отдавать
  понятную ошибку клиенту при превышении лимита.
- **Заметки:** Вопрос: если в конфигурации уже ограничено до 5 MB,
  нужна ли дополнительная валидация? Ответ — да, потому что
  ограничение в YAML влияет только на multipart-конфигурацию, но
  не защищает от прямого чтения файла в сервисе без явной проверки.

### [ ] Логи на уровне INFO содержат полные ключи из S3
- **Категория:** Безопасность, наблюдаемость
- **Описание:** Сообщение `log.info("... files={}", newAvatarPaths)` выводит
  в логи внутреннюю структуру ключей (включая `storagePath`, `userId`, UUID). 
  Это может считаться чувствительной информацией и в продакшене попадёт в централизованное хранилище логов.
- **Что делать:** Понизить уровень до DEBUG или замаскировать ключи (оставлять последние символы),
  чтобы снизить риск утечки структуры хранилища.
- **Заметки:** Сейчас для команды это не критично, но стоит зафиксировать возможный риск.
