# Журнал техдолга по сервису пользователей

Фиксирует отложенные задачи и технический долг.
Для записи: категория, описание и детали проблемы, направления решений.

## Формат записи

- Статусы задачи: `[ ]`, `[x]`.
- Блоки: **Описание**, **Что делать**, **Возможные решения**, **Заметки**.

## Записи

### [ ] Операции с аватаром не требуют аутентификации и авторизации
- **Категория:** Безопасность, авторизация
- **Описание:** В `UserAvatarController` отсутствуют ограничения доступа (`@PreAuthorize`, `@SecurityRequirement`), а в
`build.gradle.kts` нет `spring-boot-starter-security`. Любой клиент, знающий `userId`, может загрузить, получить или
удалить аватар другого пользователя. Нет ни проверки владения, ни базовой аутентификации — сервис открыт наружу.
- **Что делать:** Подключить Spring Security, настроить аутентификацию, ввести авторизационные проверки на уровне
контроллера/сервиса (например, проверять, что `userId` совпадает с идентификатором в токене), обновить OpenAPI и тесты.
- **Возможные решения:** OAuth2 Resource Server + JWT, метод `@PreAuthorize("hasAuthority('users:write') and #userId ==
principal.id")`, интеграция с gateway, контрактные тесты на отказ при доступе к чужому ресурсу.

### [ ] DTO и ответы API раскрывают внутренние ключи S3
- **Категория:** API-дизайн, безопасность
- **Описание:** `UploadAvatarResponse` и `DeleteAvatarResponse` возвращают `AvatarObjectPathsDto` с прямыми ключами из
S3 (`avatars/{userId}/{uuid}/...`). Тот же DTO применяется при генерации публичных ссылок `getAvatar`, поэтому клиенты
получают значения, которые предназначались для внутреннего контура. Это раскрывает структуру бакета, усложняет изменение
схемы хранения и повышает риск утечки ключей.
- **Что делать:** Развести модели для внутренних ключей и публичных представлений или заменить ответ на технический
идентификатор аватара/подписанные URL. При миграции задокументировать новый контракт и адаптировать интеграции.
- **Возможные решения:** `AvatarStoragePaths` для внутренних операций, `AvatarLinksDto` для ответа, слой
мапперов/преобразований, версия API с явным разделением моделей.

### [ ] Presigned URL живут слишком долго и не конфигурируются по видам
- **Категория:** S3, безопасность
- **Описание:** `S3Properties` задаёт `urlExpiration` по умолчанию в 120 часов, и этот срок применяется ко всем URL из
`S3Service.generatePresignedUrl`. Для публичных ссылок такой TTL избыточен: утерянный URL даёт доступ к файлу на пять
суток. Также нет разделения сроков для превью/оригинала и отсутствует возможность оперативно уменьшить TTL без новой
сборки.
- **Что делать:** Вынести срок жизни в конфигурацию с профилями (dev/prod), добавить отдельные настройки на тип версии,
предусмотреть ручной принудительный отзыв ссылок и мониторинг использования.
- **Возможные решения:** Конфигурация `Duration` в `application.yaml`, `ClientOverrideConfiguration` с проверкой TTL,
генерация одноразовых URL через CloudFront/STS.

### [ ] Валидатор доверяет MIME-типу из запроса без проверки содержимого
- **Категория:** Безопасность, валидация
- **Описание:** `ResourceValidator` полагается на `MultipartFile.getContentType()` и расширение файла, которые присылает
клиент. Достаточно загрузить файл с поддельным `Content-Type`, чтобы пройти проверку и сохранить в S3 произвольное
содержимое. Дополнительной проверки «магических чисел» или попытки прочитать заголовки изображения нет, поэтому сервис
не защищён от поломки ресайза и XSS/троянов в SVG.
- **Что делать:** Добавить серверное определение MIME-типа (Tika, ImageIO) и проверять сигнатуры до передачи в
`thumbnailator`, логировать расхождения и блокировать подозрительные файлы.
- **Возможные решения:** Apache Tika, `Files.probeContentType`, кастомные инспекторы заголовков для JPEG/PNG/WebP,
библиотека metadata-extractor.

### [ ] Маппинг MIME → расширение не расширяем через конфигурацию
- **Категория:** Валидация, расширяемость
- **Описание:** `ResourceValidator` держит соответствия MIME-типов и расширений в статических `Map`. Добавление нового
формата через `user.avatar.allowed-mime-types` ничего не даст — валидатор всё равно выбросит `DataValidationException`.
- **Что делать:** Перенести словари в `AvatarProperties`, валидировать конфигурацию при старте и использовать их в
валидаторе, чтобы новые форматы добавлялись без изменения кода.
- **Возможные решения:** Yaml-конфигурация с биндингом Map, поддержка нескольких расширений на MIME, автотесты на новые
форматы.

### [ ] Отсутствует проверка верхней границы размера загружаемого файла
- **Категория:** Валидация входных данных
- **Описание:** Валидатор гарантирует, что файл не пустой, но не ограничивает его максимальный размер
(`getValidatedExtension` проверяет лишь `file.getSize() <= 0`). После этого `readFileBytes` считывает содержимое
полностью в память. Большой или специально сформированный файл приведёт к перерасходу памяти/CPU и может положить сервис
.
- **Что делать:** Добавить настройку (например, `user.avatar.maxFileSize`) и проверять её до чтения в память, а также
отдавать понятную ошибку клиенту при превышении лимита.

### [ ] Нет валидации габаритов исходного изображения
- **Категория:** Валидация, устойчивость
- **Описание:** `ResourceValidator` проверяет только MIME и расширение, а `AvatarService.readFileBytes` и
`ImageResourceService.resize` принимают любой файл, даже если у него миллионы пикселей. PNG/JPEG с малым весом, но
огромной шириной/высотой приведут к выделению гигантских буферов и долгому ресайзу, что позволяет устроить DoS. Границ
на разрешение или количество пикселей нет.
- **Что делать:** Считать метаданные изображения до ресайза, ограничить максимальную ширину/высоту и количество пикселей
, логировать отклонения и возвращать клиенту понятную ошибку.
- **Возможные решения:** Использовать `ImageIO`/`metadata-extractor` для чтения размеров до загрузки в память,
конфигурацию `user.avatar.maxPixels`, отдельную проверку для квадратности и aspect ratio, юнит-тесты на злобные файлы.

### [ ] Логирование имени файла аватара на INFO раскрывает PII
- **Категория:** Безопасность, наблюдаемость
- **Описание:** `UserAvatarController.uploadAvatar` фиксирует в логах уровень INFO с `fileName={}`. Имя файла часто
содержит ФИО или адрес почты пользователя, поэтому при агрегации логов в централизованном хранилище распространяем
персональные данные.
- **Что делать:** Переключить лог на DEBUG, либо анонимизировать значение (хеш, усечённое имя) и добавить пояснение в
документацию по-безопасному логированию.
- **Возможные решения:** Маскирование строк утилитой, MDC с идентификатором запроса вместо имени файла, фильтры logback.

### [ ] Логи на уровне INFO содержат полные ключи из S3
- **Категория:** Безопасность, наблюдаемость
- **Описание:** Сообщение `log.info("... files={}", newAvatarPaths)` выводит в логи внутреннюю структуру ключей (включая
`storagePath`, `userId`, UUID). Это может считаться чувствительной информацией и в продакшене попадёт в централизованное
хранилище логов.
- **Что делать:** Понизить уровень до DEBUG или замаскировать ключи (оставлять последние символы), чтобы снизить риск
утечки структуры хранилища.

### [ ] Новые файлы аватара в S3 не откатываются при сбоях после загрузки
- **Категория:** S3, транзакционность
- **Описание:** В `uploadAvatar` новые ключи сначала загружаются в S3, затем обновляется сущность, и удаляются старые
объекты. Если на любом шаге после `storeObject` (например, при сохранении пользователя) произойдёт исключение, новые
объекты останутся в бакете, потому что их удаление не предусмотрено ни в `uploadResizedVersions`, ни в обработке
`userService.save`. Это создаёт утечки «осиротевших» файлов.
- **Что делать:** Перенести физическое удаление в S3 на фазу после успешного коммита (через
`TransactionSynchronizationManager`/`afterCommit`), либо возвращать старые ключи в случае ошибки, чтобы данные
оставались консистентными.
- **Возможные решения:** Staging → Promote + TTL; S3 Versioning + `versionId`; Outbox + воркер (саговая модель);
Direct-to-S3 + confirm; after-commit hook; локальная компенсация; отдельный реапер/инвентаризация.

### [ ] Удаление аватара чистит S3 до фиксации транзакции БД
- **Категория:** S3, транзакционность
- **Описание:** В `AvatarService.deleteAvatar` вызов `deleteAvatarObjects` отправляет удаления в S3 ещё до того, как
Hibernate сохранит пользователя с обнулёнными полями аватара. При исключении на `userService.save` транзакция БД
откатится, но файлы уже удалены из бакета — пользователь останется с ссылками на несуществующие объекты.
- **Что делать:** Перенести физическое удаление на post-commit-хук либо реализовать компенсацию, которая при откате
транзакции восстанавливает старые ключи, чтобы синхронизировать С3 и базу данных.
- **Возможные решения:** `TransactionSynchronizationManager.afterCommit`, отложенная очередь удаления, сохранение старых
ключей и повторная запись при откате, переключение порядка операций на «сначала БД, потом S3».

### [ ] Нет защиты от гонок при одновременных загрузках, возможны утечки в S3
- **Категория:** Конкурентность, S3
- **Описание:** Сущность `User` не содержит поля `@Version`, а `uploadAvatar` работает в схеме «прочитал → залил новые
файлы → сохранил → удалил старые». Если два клиента загрузят аватар почти одновременно, второй сохранит свои ключи, а
первый удалит только прежние (`oldAvatarPaths`) и оставит новые ключи второго запроса нетронутыми. В итоге в S3
останется неиспользуемый набор файлов, а состояние в БД уже другое.
- **Что делать:** Добавить оптимистическую версию для сущности пользователя, расширить Liquibase-скрипт демо-данных
столбцом `version` со значением по умолчанию, реализовать обработку конфликтов версий при загрузке аватара с очисткой
временных файлов S3 и новым доменным исключением и кодом ошибки, задокументировать возможный ответ `409 Conflict` в
OpenAPI и README.

### [ ] Частичный успех `uploadResizedVersions` оставляет временные файлы
- **Категория:** S3, обработка ошибок
- **Описание:** В `AvatarService.uploadResizedVersions` поочерёдно вызываются `resize` и `s3Service.storeObject` для
трёх версий. Если ошибка возникнет после сохранения превью (например, при записи профайл-версии или оригинала), то уже
созданные ключи останутся в бакете: метод бросает исключение, а компенсация не выполняется.
- **Что делать:** Собрать ключи в список, попытаться удалить успешно загруженные объекты при любом исключении и добавить
мониторинг повторяющихся сбоев.
- **Возможные решения:** try/finally с вызовом `removeObject`; отдельный реестр временных ключей и отложенный реапер;
выполнение загрузки через batch/transaction API S3.

### [ ] Частичный успех `deleteAvatarObjects` оставляет данные в неконсистентном состоянии
- **Категория:** S3, обработка ошибок
- **Описание:** Метод удаляет ключи последовательно через `forEach`. Если удаление превью пройдёт успешно, а удаление
оригинала выбросит `FileStorageException`, цикл оборвётся: часть файлов уже стерта, а остальные останутся. Исключение
поднимется и транзакция БД откатится, поэтому пользователь продолжит ссылаться на превью, которого уже нет в хранилище.
- **Что делать:** Собирать результаты удаления, не прерывая цикл на первой ошибке, и по завершении принимать решение —
повторно удалять оставшиеся ключи или аккумулировать ошибки и возвращать агрегированное исключение без потери информации
.

### [ ] Удаление аватара не идемпотентно при отсутствующих ключах
- **Категория:** S3, устойчивость API
- **Описание:** `deleteAvatar` вызывает `s3Service.removeObject`, который оборачивает любой `SdkException` в
`FileStorageException`. Повторный запрос после частичного удаления (или ручного удаления файла в бакете) приведёт к 500,
потому что отсутствие ключа трактуется как ошибка хранилища.
- **Что делать:** Явно обрабатывать `NoSuchKey`/`404`, логировать предупреждение и продолжать, чтобы операция удаления
стала идемпотентной для клиента.
- **Возможные решения:** Использовать `DeleteObjectResponse#deleteMarker`, проверять код ошибки SDK, оборачивать
результат в собственный объект с флагами «файл найден/нет».

### [ ] Ошибки удаления старого аватара заглушаются и ведут к утечкам в S3
- **Категория:** S3, наблюдаемость
- **Описание:** В `AvatarService.uploadAvatar` блок `try/catch` вокруг `deleteAvatarObjects` лишь пишет WARN и не
инициирует повторное удаление. При устойчивых ошибках старые ключи навсегда остаются в бакете, а метрики/алерты
отсутствуют.
- **Что делать:** Ввести повторные попытки, алертинг по числу неудачных удалений и план очистки, который не позволит
копиться лишним файлам.
- **Возможные решения:** Повтор с экспоненциальной задержкой и лимитом попыток, отправка задач в очередь очистки,
мониторинг S3 по метрике неудачных удалений.

### [ ] Пайплайн ресайза держит все версии изображения в памяти
- **Категория:** Производительность, ресурсы
- **Описание:** `AvatarService.uploadAvatar` читает файл в `byte[]`, затем держит в памяти оригинал, превью и профиль
одновременно, пока не завершится загрузка всех объектов в S3. Для изображений в несколько мегабайт это даёт трёхкратное
потребление памяти на поток и увеличивает паузы GC. При массовых загрузках сервис начнёт испытывать нехватку heap.
- **Что делать:** Перейти на потоковую обработку: сохранять оригинал сразу после чтения, ресайзить из исходного потока,
выгружая результат по мере готовности, либо использовать временные файлы/буферы с ограничением размера.
- **Возможные решения:** `InputStream` → `PipedInputStream`/`PipedOutputStream`, Thumbnailator `asFiles` с временными
файлами, использование Reactor/Async IO, лимиты `MultipartResolver` на память.

### [ ] S3-клиент не настраивает таймауты и политику повторов
- **Категория:** Устойчивость, S3
- **Описание:** `S3Config` строит `S3Client` и `S3Presigner` с настройками по умолчанию AWS SDK. Не заданы таймауты
подключения/чтения, лимит потоков и политика повторов. При сетевых проблемах запрос может зависнуть на минуты, а при
кратковременных ошибках 5xx мы сразу падаем, не попытавшись повторить операцию.
- **Что делать:** Внедрить `ClientOverrideConfiguration` с ограничением таймаутов, включить `RetryPolicy` с
экспоненциальной задержкой, параметризовать настройки через `application.yaml` и добавить метрики по количеству ретраев.
- **Возможные решения:** `ApacheHttpClient.builder()` с кастомными таймаутами, `RetryMode.ADAPTIVE`, интеграция с
Resilience4j.

### [ ] Объекты в S3 сохраняются без шифрования и политик хранения
- **Категория:** S3, безопасность
- **Описание:** `S3Service.storeObject` формирует `PutObjectRequest` только с `contentType`. Не задаётся серверное
шифрование, класс хранения, ограничения на кэширование и срок жизни. Для production-окружения это нарушает требования по
защите персональных данных и контроль стоимости хранения.
- **Что делать:** Поддержать настройки SSE (KMS/SSE-S3), lifecycle policy и заголовки кэширования через конфигурацию и
внедрить проверку того, что они применяются.
- **Возможные решения:** Добавить поля в `S3Properties`, использовать `PutObjectRequest.Builder` для
`serverSideEncryption`, `storageClass`, `cacheControl`, валидировать конфигурацию при старте.

### [ ] Конфигурация S3 заточена под локальное MinIO
- **Категория:** S3, конфигурация/безопасность
- **Описание:** `S3Config` всегда включает path-style и требует endpoint/ключи из настроек, используя
`StaticCredentialsProvider`. В AWS с IAM-ролями такой подход не работает: нет поддержки стандартной Default Credentials
Chain и нельзя отключить path-style.
- **Что делать:** Сделать endpoint и path-style опциональными, добавить выбор провайдера учётных данных (по умолчанию —
`DefaultCredentialsProvider`), предусмотреть профиль для настоящего AWS.
- **Возможные решения:** Флаг в `S3Properties`, бины `AwsCredentialsProvider` с условной конфигурацией, использование
`@ConditionalOnProperty` для MinIO-настроек.

### [ ] Локальный docker-compose открывает бакет MinIO публично
- **Категория:** Инфраструктура, безопасность
- **Описание:** В `docker-compose.yml` сервис `mc` выполняет `mc policy set public` для бакета `corpbucket`. Даже на
локалке это создаёт привычку работать с публичным бакетом и может утечь в боевые пайплайны, если скопировать
конфигурацию.
- **Что делать:** Сделать политику приватной по умолчанию, а публичный доступ включать явным флагом для отладки.
Дополнительно задокументировать риски копирования конфигурации в прод.
- **Возможные решения:** Переменная окружения для политики, скрипт инициализации с выбором public/private, проверка в CI
, что в прод-конфигурациях политика остаётся закрытой.

### [ ] Конфигурация клиентов project/payment не поддерживается кодом
- **Категория:** Конфигурация, документация
- **Описание:** В `application-local.yaml` и `application-prod.yaml` описаны URL `clients.project-service` и
`clients.payment-service`, но в коде нет бинов или клиентов, которые их используют. Разработчики могут ошибочно считать,
что интеграция существует, и менять значения, ожидая эффект.
- **Что делать:** Либо удалить неиспользуемые настройки, либо описать планируемые интеграции и задокументировать, что
параметры зарезервированы под будущие сервисы.
- **Возможные решения:** Очистка YAML, отдельный README по интеграциям, создание заглушечных клиентов с TODO и метками
"не готово".

### [ ] Неиспользуемые зависимости раздувают сборку
- **Категория:** Сборка, зависимости
- **Описание:** В `build.gradle.kts` подключены `spring-cloud-starter-openfeign`, Redis (
`spring-boot-starter-data-redis`, `jedis`, `testcontainers-redis`) и `jackson-dataformat-csv`, но в коде нет бинов,
клиентов или сериализации, которые бы их использовали. Это увеличивает время сборки, размер образа и поверхность атаки
зависимостей.
- **Что делать:** Удалить неиспользуемые артефакты или спланировать фичи, которым они действительно нужны (например,
клиент внешнего сервиса, кэш или экспорт в CSV).
- **Возможные решения:** Очистка зависимостей, отдельные модули для интеграций, документация планов по использованию
Redis/Feign.

### [ ] Юнит-тесты сведены к пустым заглушкам
- **Категория:** Тестирование, качество
- **Описание:** Классы `AvatarServiceTest`, `ImageResourceServiceTest`, `UserServiceTest`, `S3ServiceTest`,
`AvatarFileNameGeneratorTest`, `ResourceValidatorTest` содержат только `@DisplayName` без тестовых методов. В результате
Jacoco показывает формальное покрытие, хотя функциональность не проверяется.
- **Что делать:** Либо реализовать полноценные модульные тесты, либо удалить заглушки, чтобы не вводить в заблуждение о
состоянии тестового покрытия.
- **Возможные решения:** Добавить тесты с моками/контейнерами, подключить Mutation Testing, пересмотреть структуру
модульных тестов.

### [ ] Порог и область измерения Jacoco не отражают реальное покрытие
- **Категория:** Качество, сборка
- **Описание:** В `build.gradle.kts` порог `jacocoTestCoverageVerification` выставлен в `0%`, а из анализа покрытия
исключены почти все пакеты (контроллеры, сервисы, конфигурации). Итоговые отчёты создают иллюзию наличия метрик, но не
сигнализируют о деградации тестов и не защищают от регресса.
- **Что делать:** Вернуть в расчёт ключевые пакеты, поднять минимальный порог и постепенно ужесточать его, чтобы Jacoco
был полезным барьером качества.
- **Возможные решения:** Удалить лишние `exclude`, установить реалистичный минимум (например, 40%), подключить проверку
в CI и добавить отчёт в PR.

### [ ] Checkstyle тянет внешний DTD и ломает офлайн-сборку
- **Категория:** Сборка, DX
- **Описание:** В `build.gradle.kts` явно включён параметр `checkstyle.enableExternalDtdLoad=true`, а
`config/checkstyle/checkstyle.xml` ссылается на DTD по HTTPS. Любой запуск `checkstyle` требует сетевого доступа,
тормозит сборку и нарушает офлайн-режим, ради которого есть `install.sh`. При недоступности checkstyle.org сборка
полностью падает.
- **Что делать:** Отключить внешнюю загрузку DTD, положить DTD локально или перейти на конфигурацию без DTD. Обновить
пайплайн и инструкцию по офлайн-режиму.
- **Возможные решения:** `configProperties["checkstyle.enableExternalDtdLoad"] = "false"`, локальная копия DTD, переход
на JSON-конфигурацию, проверка в CI на отсутствие сетевых запросов.
